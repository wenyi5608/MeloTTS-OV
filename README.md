<div align="center">
  <div>&nbsp;</div>
  <img src="logo.png" width="300"/> 
</div>

<details>
  <summary>Click here to expand/collapse content</summary>
  <ul>
## Introduction
MeloTTS is a **high-quality multi-lingual** text-to-speech library by [MIT](https://www.mit.edu/) and [MyShell.ai](https://myshell.ai). Supported languages include:

| Language | Example |
| --- | --- |
| English (American)    | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/en/EN-US/speed_1.0/sent_000.wav) |
| English (British)     | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/en/EN-BR/speed_1.0/sent_000.wav) |
| English (Indian)      | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/en/EN_INDIA/speed_1.0/sent_000.wav) |
| English (Australian)  | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/en/EN-AU/speed_1.0/sent_000.wav) |
| English (Default)     | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/en/EN-Default/speed_1.0/sent_000.wav) |
| Spanish               | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/es/ES/speed_1.0/sent_000.wav) |
| French                | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/fr/FR/speed_1.0/sent_000.wav) |
| Chinese (mix EN)      | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/zh/ZH/speed_1.0/sent_008.wav) |
| Japanese              | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/jp/JP/speed_1.0/sent_000.wav) |
| Korean                | [Link](https://myshell-public-repo-host.s3.amazonaws.com/myshellttsbase/examples/kr/KR/speed_1.0/sent_000.wav) |

Some other features include:
- The Chinese speaker supports `mixed Chinese and English`.
- Fast enough for `CPU real-time inference`.

## Usage
- [Use without Installation](docs/quick_use.md)
- [Install and Use Locally](docs/install.md)
- [Training on Custom Dataset](docs/training.md)

The Python API and model cards can be found in [this repo](https://github.com/myshell-ai/MeloTTS/blob/main/docs/install.md#python-api) or on [HuggingFace](https://huggingface.co/myshell-ai).

## Join the Community

**Discord**

Join our [Discord community](https://discord.gg/myshell) and select the `Developer` role upon joining to gain exclusive access to our developer-only channel! Don't miss out on valuable discussions and collaboration opportunities.

**Contributing**

If you find this work useful, please consider contributing to this repo.

- Many thanks to [@fakerybakery](https://github.com/fakerybakery) for adding the Web UI and CLI part.

## Authors

- [Wenliang Zhao](https://wl-zhao.github.io) at Tsinghua University
- [Xumin Yu](https://yuxumin.github.io) at Tsinghua University
- [Zengyi Qin](https://www.qinzy.tech) at MIT and MyShell

**Citation**
```
@software{zhao2024melo,
  author={Zhao, Wenliang and Yu, Xumin and Qin, Zengyi},
  title = {MeloTTS: High-quality Multi-lingual Multi-accent Text-to-Speech},
  url = {https://github.com/myshell-ai/MeloTTS},
  year = {2023}
}
```

## License

This library is under MIT License, which means it is free for both commercial and non-commercial use.

## Acknowledgements

This implementation is based on [TTS](https://github.com/coqui-ai/TTS), [VITS](https://github.com/jaywalnut310/vits), [VITS2](https://github.com/daniilrobnikov/vits2) and [Bert-VITS2](https://github.com/fishaudio/Bert-VITS2). We appreciate their awesome work.

  </ul>
</details>

## Update Notes
### 2024/08/21
* MeloTTS model supports using openvino to accelerate the inference process. Currently only verified on Linux system.
### 2024/08/28
* TTS and Bert model support int8 quantize.

### 2024/09/22
* Enable BERT for NPU on Meteor Lake architecture


## Install MeloTTS with OpenVINO™

```
pip install -r requirements.txt
pip install openvino nncf
python setup.py develop # or  pip install -e .
python -m unidic download
pip install deepfilternet #optional for enhancing speech
```

## Convert MeloTTS model to OpenVINO™ IR(Intermediate Representation) and testing:
```shell
python3  test_tts.py
```

## Demo
Here are the audio files generated by the int8 quantized model from OpenVINO.

| Language             | Example |
|----------------------|---------|
| English (American)   | [Link](https://github.com/zhaohb/MeloTTS-OV/blob/speech-enhancement-and-npu/demo/ov_en_int8_EN-US.wav)    |
| English (British)    | [Link](https://github.com/zhaohb/MeloTTS-OV/blob/speech-enhancement-and-npu/demo/ov_en_int8_EN-BR.wav)   |
| English (Indian)     | [Link](https://github.com/zhaohb/MeloTTS-OV/blob/speech-enhancement-and-npu/demo/ov_en_int8_EN_INDIA.wav)    |
| English (Australian)  | [Link](https://github.com/zhaohb/MeloTTS-OV/blob/speech-enhancement-and-npu/demo/ov_en_int8_EN-AU.wav)   |
| English (Default)    | [Link](https://github.com/zhaohb/MeloTTS-OV/blob/speech-enhancement-and-npu/demo/ov_en_int8_EN-Default.wav)    |
| Chinese  (mix EN)            | [Link](https://github.com/zhaohb/MeloTTS-OV/blob/speech-enhancement-and-npu/demo/ov_en_int8_ZH.wav)    |
### Todo:
1. Now the input will be split and processed serially. This can be optimized to use openvino asynchronous inference, like this:
```python
  ...
    self.tts_model = self.core.read_model(Path(ov_model_path))
    self.tts_compiled_model = self.core.compile_model(self.tts_model, 'CPU')
    self.tts_request_0 = self.tts_compiled_model.create_infer_request()
    self.tts_request_1 = self.tts_compiled_model.create_infer_request()
  ...
    for index, t in enumerate(texts):
      ...
        if index == 0:
          self.tts_request_0.start_async(inputs_dict, share_inputs=True)
        elif index ==1 :
          self.tts_request_1.start_async(inputs_dict, share_inputs=True)
      ...
    self.tts_request_0.wait()
    self.tts_request_1.wait()
  ...
```


